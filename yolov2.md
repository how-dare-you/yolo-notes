# Batch Normalization

![](/images/yolov2/yolov2_2023-03-02-10-21-23.png)

在卷积层后使用BN可以在训练时让模型更快收敛，BN也起到正则化的作用。【正则化用于防止模型过拟合【过拟合指的是模型在训练集表现好，但是在测试集上表现差】】。

正则化通过减少变量的大小【让值域处于0-1】来保持模型中的所有变量或特征。

#  fully convolutional  

- v1 使用网络顶部的全连接层进行预测
- v2 去除了全连接层
- 一般大的物体会出现在图像中心，所以输出的网格大小应该是奇数，这样刚好中心只有一个网格用于预测物体。v2 的输入 416 * 416，输出特征图大小为 13 * 13

![](/images/yolov2/yolov2_2023-03-02-10-31-42.png)


# Anchor boxes 

- v2 使用锚框预测物体边界框
- 与 v1 的 bounding boxes 不同的是锚框有人为预设的大小形状，预设形状通过对数据集中的物体形状进行聚类得到，与物体所处的位置无关。
- v1 直接预测 bounding box 的宽高，而 v2 预测边界框与 anchor box 的宽高偏移量，比起直接预测，基于锚框宽高预测的偏移量对网络来说更容易些。
- v1 每一个网格单元最终只能够预测得到一个物体类别，而v2可以为每一个网格中的每一个锚框预测一个类别，因此v2的一个网格单元可以有预测得到多种类别。
- 与真实框 IOU 最高的锚框就是预测框


# direct location prediction

![](/images/yolov2/yolov2_2023-03-02-10-51-13.png)

## 边界框参数 

- 每一个预测框依然有 cxywh 五个参数。
- $t_x$ $t_y$ 用于计算物体中心坐标的偏移量，通过每个网格已知的宽高可以换算出物体在图像中的中心坐标。

![](/images/yolov2/yolov2_2023-03-02-10-51-53.png)

- $t_w$ $t_h$ 用于计算物体宽高的偏移量，通过锚框已知的宽高$p_w$ $p_h$可以换算出物体在图像中的宽高。


 
![](/images/yolov2/yolov2_2023-03-02-11-03-20.png)


- $t_o$ 用于计算置信度 $\sigma(t_o)$ 
> sigmoid 函数也叫 Logistic 函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间。


# Passthrough Layer 

- passthrough 层将 26 * 26 * 512 的特征图 转换为 13 * 13 * 2048 大小的特征图。

![](/images/yolov2/yolov2_2023-03-02-11-15-03.png)

# YOLOv2 Darknet-19

- 有19个卷积层，5个最大池化层
- 池化层后的通道数翻倍
- 依旧使用 1 * 1 卷积核减少通道大小
- 每一层卷积后使用BN
![](/images/yolov2/yolov2_2023-03-02-11-16-44.png)
