# Refs
- https://www.youtube.com/watch?v=NAwleAip-9Q&list=PLcukxafm1F_7mLINZY-Slv8dMYYuffmsB&index=10&t=877s
- https://marketplace.visualstudio.com/items?itemName=mushan.vscode-paste-image

# 目标检测-概念
目标检测是找到每个感兴趣对象的位置和类，为每个检测到的对象绘制边界框【bounding box】(边界框可以表示物体的位置和形状),以及识别每一个物体的类别；    

![](/images/yolov1/yolov1_2023-03-01-08-26-47.png)


![](/images/yolov1/yolov1_2023-03-01-08-30-25.png)

# YOLO 

在YOLO算法中，将目标检测问题转换为了对每一个物体的边界框和类别的回归预测；

在推理阶段，输入一张图片，只需要经历一次传播就可以得到图片中所有物体的边界框和类别的预测值。正如YOLO的缩写强调的那样，只需要看一眼就知道结果。

在训练阶段，YOLO通过输入包含了物体的上下文关系的整张图片来学习，利用整张图像的特征来对每一个物体进行学习，使得YOLO可以更好的学习理解物体可能出现的周围信息。

# Grid Cells and Bounding Boxes 

![](/images/yolov1/yolov1_2023-03-01-08-51-54.png)

在将整张图片输入网络的过程中，YOLO将输入的图像划分为 S * S 的网格单元，例如在YOLOv1 的论文中，作者设置S = 7,即将图像划分为49个网格单元。

每一个网格单元最终只能够预测得到一个物体类别，只有包含物体中心的网格单元负责检测物体。

如果一个网格单元出现多个物体，最终也只能预测其中一个。这也就是为何YOLOv1对于鸟群等密集的、小的物体，检测效果不佳的原因，


每一个网格单元会预测出 B 个 bounding boxes，每个 bounding box 包含物体的 位置、大小、置信度 confidence 【C,x,y,w,h】共5个值。在论文中，作者设置 B = 2。

![](/images/yolov1/yolov1_2023-03-01-09-10-40.png)

其中 xy 表示物体在图像中的中心点坐标。不过不是直接根据图像大小得到的坐标，而是基于网格单元左上角为（0,0）的坐标，对其归一化处理。

![](/images/yolov1/yolov1_2023-03-01-09-13-38.png)


其中 wh 表示物体的宽高，同样根据整张图片将宽高归一化至区间0-1之间。

![](/images/yolov1/yolov1_2023-03-01-09-23-49.png)

最后，confidence 表示预测的得分，在训练阶段，confidence越高，表示预测情况和真实情况拟合的越好。

训练阶段的置信度由 bounding box 是否包含物体和其与真实框的IOU决定。在每一轮优化训练中，预测框会改变，IOU也随之改变，所以置信度也会不断在变化。

因为每一个网格单元最终只能够预测得到一个物体类别，所以当网格单元出现物体时，bounding boxes 中和真实框 IOU 值最高的才会来负责检测网格中的物体。其他 IOU 值较低的 box 就会被抛弃掉。通过每次选择 IOU 最高的 box，来不断拟合真实框的形状和大小。

但这也导致了 YOLOv1 的bounding boxes 只会对训练集中已有的物体形状大小去拟合，很难去预测在测试集中出现不同尺寸和形状的物体。



![](/images/yolov1/yolov1_2023-03-01-09-30-17.png)

训练阶段的 confidence 计算，如果网格单元不存在物体，置信度为0，否者为 box 与 真实框的 IOU。

![](/images/yolov1/yolov1_2023-03-01-09-48-13.png)

除了学习矩形框的 cxywh 五个值外，还会学习网格单元存在物体时，其各类别的条件概率。



![](/images/yolov1/yolov1_2023-03-01-09-51-50.png)

对于 S * S 的网格，每个网格有 B 个 bounding boxes ，有 N 个需要预测的类别，网络的输出为 S * S * (B * 5 + N) 。例如论文中的S = 7,B = 2,N = 20,其输出形状为 7 * 7 * （2 * 5 + 20）。

![](/images/yolov1/yolov1_2023-03-01-10-16-44.png)

# YOLOv1 网络 

YOLOv1 有 24 层卷积层，两个全连接层。

其中 1 * 1 卷积核为了减少通道数，连续的 3 * 3 卷积提供了更大的感受野。

YOLOv1 使用 VOC 数据集训练，输入图像分辨率为 448 * 448 ，最后输出 7 * 7 * 30。

对输出层使用线性激活函数，其他层使用 LeakyReLU 激活函数。

![](/images/yolov1/yolov1_2023-03-01-10-30-05.png)

# YOLOv1 训练阶段 

在 imagenet 上预训练，后面操作技巧详细请查看论文。

# Loss 损失函数

![](/images/yolov1/yolov1_2023-03-01-10-38-59.png)

训练时使用 MSE 均方误差 计算位置、置信度和类别概率的误差。

v1对于大物体和小物体的宽高损失计算仍有改进空间。

## 定位误差

![](/images/yolov1/yolov1_2023-03-01-14-30-01.png)

损失函数前两项，计算了物体中心点和其宽高的误差，其中 λ_coord 表示的是一个权重，与之对应的还有函数的第四项中的 λ_noobj，前者只有存在物体时计算，后者反之。由于整张图片往往是不存在物体的网格单元占了大多数，所以希望给予有物体的单元格计算更多的关注，降低无物体的关注。在论文中，作者分别设置为5和0.5。

函数项中的 i 表示第 i 个图像中的网格单元，j 表示第 j 个网格单元中的 bounding box。后面跟个一个控制函数 $\mathbb{1}^{obj}_{ij}$ 表示当前网格单元的box是否包含物体，定位误差只有在负责检测物体时存在才有意义，不负责物体检测时，该两项均等于0。

为了让大小物体的形状误差尽可能类似，在第二项中对宽高进行开根号，用于加强对小物体的误差计算。

## 置信度误差 

![](/images/yolov1/yolov1_2023-03-01-14-36-17.png)

第三第四项负责计算各个 bounding boxes 的置信度误差，对于第三项，只对负责检测物体的 box 生效，其中 $\hat{C_i}$ 置信度为预测框与真实框的 IOU。在训练过程中，$C_i$ 等于1，这一误差项是为了让预测框与真实框的 IOU 不断趋近于1，即预测框与真实框几乎完全重合。

第四项计算的是那些不负责检测物体的 boxes，它们的置信度等于0。这一项是为了说明该网格中没有物体存在，没有需要去检测的 box 。在训练过程中，这里的 $C_i$ 等于0，即表示这里不存在物体，没有真实框需要去计算 IOU。

## 分类误差

![](/images/yolov1/yolov1_2023-03-01-15-01-51.png)

最后一项用于计算网格单元中存在物体时的 box 的类别概率，每一个网格单元最终只能够预测得到一个物体类别，不论每个网格有多少个 bounding boxes。


# 推理预测

![](/images/yolov1/yolov1_2023-03-01-10-41-32.png)

v1使用没有经过其他特征处理的特征图对所有尺寸的物体进行预测，对不同尺寸的物体检测效果仍有改进空间。

# 预测后处理

将置信度低的过滤掉，利用 NMS 去除同一个物体多余的预测框。

![](/images/yolov1/yolov1_2023-03-01-10-43-17.png)

![](/images/yolov1/yolov1_2023-03-01-10-42-53.png)

![](/images/yolov1/yolov1_2023-03-01-10-43-01.png)